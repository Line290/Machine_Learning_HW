{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_validation import KFold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "import sklearn\n",
    "\n",
    "N_ESTIMATORS = 100\n",
    "# No feature selection above basics. I'll just let the Random Forest do its thing.\n",
    "IGNORE_LIST = ['id', 'profit', 'responded', 'pmonths']\n",
    "CUTOFF = 0.5\n",
    "\n",
    "def k_split(df, k):\n",
    "    \"\"\"\n",
    "    Split the training.csv set into k-folds, stored as a train, test dictionaries\n",
    "    \"\"\"\n",
    "    train = {}\n",
    "    test = {}\n",
    "    kf = KFold(len(df), k, shuffle=True)\n",
    "    i = 0\n",
    "    for train_index, test_index in kf:\n",
    "        train[i] = df.ix[train_index]\n",
    "        test[i] = df.ix[test_index]\n",
    "        i += 1\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def refactor(df):\n",
    "    \"\"\"\n",
    "    Make non-numerical data fields numerical with int factors\n",
    "    Save the factor definitions in a dictionary for later\n",
    "    \"\"\"\n",
    "    factors = {}\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype not in [float, int]:\n",
    "            factors[c] = {}\n",
    "            i = 0\n",
    "            for f in df[c].dropna().unique():\n",
    "                factors[c][f] = i\n",
    "                i += 1\n",
    "    for c, d in factors.iteritems():\n",
    "        for k, v in d.iteritems():\n",
    "            df.ix[df[c] == k, c] = int(v)\n",
    "    return df, factors\n",
    "\n",
    "\n",
    "def rf_predict(train, test, col, n=100, prob=False, ignore_list=['id', 'profit', 'responded', 'pmonths'], classifier='AdaBoostClassifier'):\n",
    "    \"\"\"\n",
    "    If you just want it to predict the field, leave prob=False. If you want the probability of 1 vs. 0, make it True.\n",
    "    Don't fit on fields that still have nulls in them (or that are chosen to be ignored)\n",
    "    Output the estimates for col in the test dataframe.\n",
    "    classifier: RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "    \"\"\"\n",
    "    if prob:\n",
    "        not_fit = ignore_list\n",
    "        not_fit.extend(train.columns[train.isnull().sum() > 0])\n",
    "        not_fit.extend(test.columns[test.isnull().sum() > 0])\n",
    "        not_fit.append(col)\n",
    "        not_fit = set(not_fit)\n",
    "#         forest = RandomForestClassifier(n_estimators=n)\n",
    "        forest = getattr(sklearn.ensemble, classifier)(n_estimators=n)\n",
    "        forest = forest.fit(train[[c for c in train.columns if c not in not_fit]], train[col])\n",
    "        output = [x[1] for x in forest.predict_proba(test[[c for c in test.columns if c not in not_fit]])]\n",
    "    else:\n",
    "        not_fit = ignore_list\n",
    "        not_fit.extend(train.columns[train.isnull().sum() > 0])\n",
    "        not_fit.extend(test.columns[test.isnull().sum() > 0])\n",
    "        not_fit.append(col)\n",
    "        not_fit = set(not_fit)\n",
    "        forest = getattr(sklearn.ensemble, classifier)(n_estimators=n)\n",
    "#         forest = RandomForestClassifier(n_estimators=n)\n",
    "        forest = forest.fit(train[[c for c in train.columns if c not in not_fit]], train[col].values.astype(np.int32))\n",
    "        output = forest.predict(test[[c for c in test.columns if c not in not_fit]])\n",
    "\n",
    "    return output, forest\n",
    "\n",
    "\n",
    "def fill_in_nan(df, col, n=100, classifier='AdaBoostClassifier'):\n",
    "    \"\"\"\n",
    "    Use the rf_predict with prob=False to guess what missing values are.\n",
    "    \"\"\"\n",
    "    output, forest = rf_predict(df[df[col].notnull()], df[df[col].isnull()], col, n, False, classifier = classifier)\n",
    "    df.ix[df[col].isnull(), col] = output\n",
    "    return df\n",
    "\n",
    "\n",
    "def calc_profit(test, prediction, cutoff):\n",
    "    \"\"\"\n",
    "    Use the profit function given to calculate profits for a certain cutoff on forest.predict_proba.\n",
    "    This is what is to be optimized vs. cutoff choice.\n",
    "    \"\"\"\n",
    "    test['prediction'] = prediction\n",
    "    test.ix[test['profit'].isnull(), 'profit'] = -30\n",
    "    return sum(test.ix[test['prediction'] >= cutoff, 'profit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:43: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    train = pd.read_csv('data/DataTraining.csv')\n",
    "    train.loc[train.default == 'unknown', 'unknown'] = 'unknownnnn'\n",
    "    train = train.replace(\"unknown\", np.nan)\n",
    "    test_original = pd.read_csv('data/DataPredict.csv')\n",
    "    \n",
    "#     print test_original.shape\n",
    "#     print train.shape\n",
    "    test_original.columns = train.columns[:-4]\n",
    "    test = test_original.copy()\n",
    "    test.loc[test.default == 'unknown', 'unknown'] = 'unknownnnn'\n",
    "    test = test.replace(\"unknown\", np.nan)\n",
    "    \n",
    "    model = 'AdaBoostClassifier'\n",
    "\n",
    "    train, train_factors = refactor(train)\n",
    "    test, test_factors = refactor(test)\n",
    "\n",
    "    train = fill_in_nan(train, 'housing', N_ESTIMATORS, model)\n",
    "    train = fill_in_nan(train, 'day_of_week', N_ESTIMATORS, model)\n",
    "    train = fill_in_nan(train, 'schooling', N_ESTIMATORS, model)\n",
    "    train = fill_in_nan(train, 'custAge', N_ESTIMATORS, model)\n",
    "    test = fill_in_nan(test, 'day_of_week', N_ESTIMATORS, model)\n",
    "    test = fill_in_nan(test, 'schooling', N_ESTIMATORS, model)\n",
    "    test = fill_in_nan(test, 'custAge', N_ESTIMATORS, model)\n",
    "    test = fill_in_nan(test, 'housing', N_ESTIMATORS, model)\n",
    "    \n",
    "    prediction, forest = rf_predict(train, test, 'responded', N_ESTIMATORS, prob=True, ignore_list=IGNORE_LIST, classifier=model)\n",
    "\n",
    "    test_original['market_to'] = [1 if p > CUTOFF else 0 for p in prediction]\n",
    "\n",
    "    test_original.to_csv('data/testingCandidate_output.csv', index=False)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################   RandomForestClassifier   ##########\n",
      "(6509, 25) (1628, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:43: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12029, 25)\n",
      "roc auc score original:  0.7403961481786094\n",
      "Best cutoff:  0.29\n",
      "Best profit:  7256.0\n",
      "Accuracy:  0.8716216216216216\n",
      "roc auc score:  0.6879696671513263\n",
      "###################   AdaBoostClassifier   ##########\n",
      "(6509, 25) (1628, 25)\n",
      "(11837, 25)\n",
      "roc auc score original:  0.7863747793062277\n",
      "Best cutoff:  0.5\n",
      "Best profit:  10819.0\n",
      "Accuracy:  0.8071253071253072\n",
      "roc auc score:  0.7215638455969211\n",
      "###################   BaggingClassifier   ##########\n",
      "(6509, 25) (1628, 25)\n",
      "(11909, 25)\n",
      "roc auc score original:  0.6664438025959207\n",
      "Best cutoff:  0.73\n",
      "Best profit:  4900.0\n",
      "Accuracy:  0.9035626535626535\n",
      "roc auc score:  0.5779756810726001\n",
      "###################   ExtraTreesClassifier   ##########\n",
      "(6509, 25) (1628, 25)\n",
      "(11813, 25)\n",
      "roc auc score original:  0.7413472111155538\n",
      "Best cutoff:  0.22\n",
      "Best profit:  8794.0\n",
      "Accuracy:  0.831081081081081\n",
      "roc auc score:  0.6678411968545914\n",
      "###################   GradientBoostingClassifier   ##########\n",
      "(6509, 25) (1628, 25)\n",
      "(11853, 25)\n",
      "roc auc score original:  0.7340423254599244\n",
      "Best cutoff:  0.63\n",
      "Best profit:  12454.0\n",
      "Accuracy:  0.8605651105651105\n",
      "roc auc score:  0.7124150686515021\n"
     ]
    }
   ],
   "source": [
    "models = ['RandomForestClassifier', \n",
    "         'AdaBoostClassifier', \n",
    "         'BaggingClassifier', \n",
    "         'ExtraTreesClassifier', \n",
    "         'GradientBoostingClassifier']\n",
    "for model in models:\n",
    "    print \"###################   {}   ##########\".format(model)\n",
    "    N_ESTIMATORS = 100\n",
    "    # df_original = pd.read_csv('data/new_train.csv')\n",
    "    df_original = pd.read_csv('data/DataTraining.csv')\n",
    "    df = df_original.copy()\n",
    "    df.loc[df.default == 'unknown', 'unknown'] = 'unknownnnn'\n",
    "    df = df.replace(\"unknown\", np.nan)\n",
    "    train_, test = k_split(df, 5)\n",
    "    train_ = train_[0]\n",
    "    test = test[0]\n",
    "    print train_.shape, test.shape\n",
    "    train_N = train_.loc[train_.responded == 'yes']\n",
    "    train_N_e = pd.concat([train_N]*((len(train_)-len(train_N))/len(train_N)), ignore_index=True)\n",
    "    train = pd.concat([train_, train_N_e], ignore_index=True)\n",
    "    train, train_factors = refactor(train)\n",
    "    test, test_factors = refactor(test)\n",
    "    print train.shape\n",
    "\n",
    "    train = fill_in_nan(train, 'housing', N_ESTIMATORS, model)\n",
    "    train = fill_in_nan(train, 'day_of_week', N_ESTIMATORS, model)\n",
    "    train = fill_in_nan(train, 'schooling', N_ESTIMATORS, model)\n",
    "    train = fill_in_nan(train, 'custAge', N_ESTIMATORS, model)\n",
    "    test = fill_in_nan(test, 'day_of_week', N_ESTIMATORS, model)\n",
    "    test = fill_in_nan(test, 'schooling', N_ESTIMATORS, model)\n",
    "    test = fill_in_nan(test, 'custAge', N_ESTIMATORS, model)\n",
    "    test = fill_in_nan(test, 'housing', N_ESTIMATORS, model)\n",
    "\n",
    "    prediction, forest = rf_predict(train, test, \n",
    "                                    'responded', \n",
    "                                    N_ESTIMATORS, \n",
    "                                    prob=True, \n",
    "                                    ignore_list=['id', 'profit', 'responded', 'pmonths'], \n",
    "                                    classifier = model)\n",
    "\n",
    "    ground_truth = test['responded'].values.astype(np.int32)\n",
    "\n",
    "\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    print \"roc auc score original: \",roc_auc_score(ground_truth, prediction)\n",
    "\n",
    "    max_profit = -1000\n",
    "    cutoff = -1\n",
    "    for i in np.linspace(0, 1, 101):\n",
    "        profit = calc_profit(test, prediction, i)\n",
    "        if profit > max_profit:\n",
    "            max_profit = profit\n",
    "            cutoff = i\n",
    "#         print '{} : {}'.format(i, profit)\n",
    "    print \"Best cutoff: \", cutoff\n",
    "    print \"Best profit: \", max_profit\n",
    "    pred = (np.asarray(prediction)>cutoff)*1\n",
    "    print \"Accuracy: \",np.mean(pred == ground_truth)\n",
    "    print \"roc auc score: \",roc_auc_score(ground_truth, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
